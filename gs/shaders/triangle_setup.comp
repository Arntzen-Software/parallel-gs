#version 450

// SPDX-FileCopyrightText: 2024 Arntzen Software AS
// SPDX-FileContributor: Hans-Kristian Arntzen
// SPDX-FileContributor: Runar Heyer
// SPDX-License-Identifier: LGPL-3.0+

#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require

//#extension GL_EXT_spirv_intrinsics : require
//spirv_execution_mode(extensions = ["SPV_KHR_float_controls"], capabilities = [4467], 4462, 32);

#define USE_RCP_FIXED
#define USE_RCP_FLOAT
#define PRIMITIVE_LIST_QUALIFIER readonly
#define PRIMITIVE_SETUP_QUALIFIER writeonly

#define NEED_VERTEX_POSITION
#define NEED_VERTEX_ATTRIBUTE
#define NEED_PRIMITIVE_SETUP
#define NEED_PRIMITIVE_ATTRIBUTE
#define NEED_TRANSFORMED_ATTRIBUTE

#include "data_buffers.h"
#include "data_structures.h"
#include "math_utils.h"
#include "intersect.h"
#include "utils.h"

layout(local_size_x = 64) in;

layout(constant_id = 0) const int SAMPLING_RATE_LOG2 = 0;

layout(push_constant) uniform Registers
{
    uint num_primitives;
    uint packed_z_shift; // Shifts depth into 32-bit buckets.
} registers;

layout(set = 0, binding = BINDING_SINGLE_SAMPLE_HEURISTIC, std430) buffer SingleSampleHeuristicSSBO
{
    SingleSampleHeuristic data;
} heuristic;

bool tie_break_rule(ivec2 edge)
{
    return (edge.y > 0) || (edge.y == 0 && edge.x < 0);
}

int shift_int64_subpixels(ivec2 c)
{
    int msb = c.y << (32 - PGS_SUBPIXEL_RASTER_BITS);
    int lsb = int(uint(c.x) >> PGS_SUBPIXEL_RASTER_BITS);
    return msb | lsb;
}

ivec3 quantize_step(int a, int b, ivec2 c)
{
    return ivec3(a, b, shift_int64_subpixels(c));
}

bool order_less_than(ivec2 a, ivec2 b, uint az, uint bz)
{
    if (bz != az)
        return az < bz;
    else if (b.y != a.y)
        return a.y < b.y;
    else
        return a.x < b.x;
}

void swap(inout ivec2 x, inout ivec2 y)
{
    ivec2 tmp = x;
    x = y;
    y = tmp;
}

void swap(inout uint x, inout uint y)
{
    uint tmp = x;
    x = y;
    y = tmp;
}

ivec2 smul32x32(int a, int b)
{
    ivec2 result;
    imulExtended(a, b, result.y, result.x);
    return result;
}

ivec2 sub64(ivec2 a, ivec2 b)
{
    uint borrow;
    uint lsb = usubBorrow(a.x, b.x, borrow);
    uint msb = a.y - b.y - borrow;
    return ivec2(lsb, msb);
}

vec2 unpack_uv(u16vec2 uv)
{
    return ldexp(vec2(uv), ivec2(-4));
}

void main_inner(uint index)
{
    ivec3 order = ivec3(0, 1, 2);

    uint state_word = primitive_attr.data[index].state;
    bool parallelogram = bitfieldExtract(state_word, STATE_BIT_PARALLELOGRAM, 1) != 0;
    bool perspective = bitfieldExtract(state_word, STATE_BIT_PERSPECTIVE, 1) != 0;
    bool iip = bitfieldExtract(state_word, STATE_BIT_IIP, 1) != 0;
    bool fix = bitfieldExtract(state_word, STATE_BIT_FIX, 1) != 0;
    bool sprite = bitfieldExtract(state_word, STATE_BIT_SPRITE, 1) != 0;
    bool line = bitfieldExtract(state_word, STATE_BIT_LINE, 1) != 0;
    bool multisample = state_is_multisample(state_word);
    uint provoking = bitfieldExtract(state_word, STATE_PARALLELOGRAM_PROVOKING_OFFSET, STATE_PARALLELOGRAM_PROVOKING_COUNT);

    VertexPosition v0 = vertex_position.data[3u * index + 0u];
    VertexPosition v1 = vertex_position.data[3u * index + 1u];
    VertexPosition v2 = vertex_position.data[3u * index + 2u];
    ivec2 a = v0.pos;
    ivec2 b = v1.pos;
    ivec2 c = v2.pos;
    uint za = v0.z;
    uint zb = v1.z;
    uint zc = v2.z;
    ivec4 primitive_bb = ivec4(primitive_attr.data[index].bb);

    // Rough approximation of bresenham. We need to handle the case where primitives expect exit rule.
    // The simplest workaround is just to offset by one sub-pixel if we observe edge case.
    // Need hardware tests to determine exactly how the rules go.
    if (line)
    {
        if (b.x > a.x)
        {
            a.x += 1;
            b.x += 1;
        }

        if (b.y > a.y)
        {
            a.y += 1;
            b.y += 1;
        }
    }

    if ((!parallelogram || line) && !fix)
    {
        // Unsure if PS2 primitives are rotationally invariant.
        // They probably are as DDA tends to sort vertices.
        // Parallelograms depend on their provoking vertex, so don't do anything funny here.
        // Select provoking vertex as top, then left.
        // We want lowest Z to be provoking to increase Z interpolation accuracy, especially in 32-bit Z.
        if (!line && !order_less_than(b, c, zb, zc))
        {
            order = order.xzy;
            swap(b, c);
            swap(zb, zc);
        }

        if (!order_less_than(a, b, za, zb))
        {
            order = order.yxz;
            swap(a, b);
            swap(za, zb);
        }
    }
    else if (provoking == 1)
    {
        order = order.yxz;
        swap(a, b);
        swap(za, zb);
    }
    else if (provoking == 2)
    {
        order = order.zyx;
        swap(a, c);
        swap(za, zc);
    }

    if (sprite)
    {
        c = ivec2(a.x, b.y);
        b = ivec2(b.x, a.y);
    }
    else if (line)
    {
        // For now, construct a simple parallelogram line.
        ivec2 ab = b - a;
        ivec2 abs_d = abs(ab);

        if (abs_d.x > abs_d.y)
        {
            // Horiz major. Ensure area is positive so we don't have to deal with reordering.
            // Make sure the width is exactly 1 pixel, and tie-break rules ensure we only get one pixel
            // hit. This emulates Bresenham rather well.
            int y_delta = -sign(ab.x) << (PGS_SUBPIXEL_BITS - 1);
            c.x = a.x;
            c.y = a.y + y_delta;
            a.y -= y_delta;
            b.y -= y_delta;
        }
        else
        {
            // Vert major. Ensure area is positive so we don't have to deal with reordering.
            int x_delta = sign(ab.y) << (PGS_SUBPIXEL_BITS - 1);
            c.x = a.x + x_delta;
            c.y = a.y;
            a.x -= x_delta;
            b.x -= x_delta;
        }
    }

    // Y or Z is selected as i/j target based on winding later.
    ivec2 ab = b - a;
    ivec2 ac = c - a;

    ivec2 signed_area = sub64(smul32x32(ab.y, ac.x), smul32x32(ab.x, ac.y));

    if (all(equal(signed_area, ivec2(0))))
    {
        // Degenerate, no pixels are rasterized.
        primitive_setup.data[index].bb = ivec4(0, 0, -1, -1);
        return;
    }

    // Signed area has a range of +/- 0xffff * 0xffff.

    uint area;

    if (signed_area.y < 0)
    {
        area = uint(-signed_area.x);
        swap(ab, ac);
        swap(b, c);
        swap(zb, zc);
        order = order.xzy;
    }
    else
    {
        area = uint(signed_area.x);
    }

    ivec2 bc = c - b;
    ivec2 ca = -ac;

    int dcdx = +ab.y;
    int dcdy = -ab.x;
    int dadx = +bc.y;
    int dady = -bc.x;
    int dbdx = +ca.y;
    int dbdy = -ca.x;

    ivec2 constant_c = sub64(smul32x32(-a.x, dcdx), smul32x32(a.y, dcdy));
    ivec2 constant_a = sub64(smul32x32(-b.x, dadx), smul32x32(b.y, dady));
    ivec2 constant_b = sub64(smul32x32(-c.x, dbdx), smul32x32(c.y, dbdy));

    bool tie_break_a = tie_break_rule(bc);
    bool tie_break_b = tie_break_rule(ca);
    bool tie_break_c = tie_break_rule(ab);
    int error_a = int(!tie_break_a);
    int error_b = int(!tie_break_b);
    int error_c = int(!tie_break_c);

    constant_a = sub64(constant_a, ivec2(error_a, 0));
    constant_b = sub64(constant_b, ivec2(error_b, 0));
    constant_c = sub64(constant_c, ivec2(error_c, 0));

    error_a += constant_a.x & (PGS_SUBPIXELS_RASTER - 1);
    error_b += constant_b.x & (PGS_SUBPIXELS_RASTER - 1);
    error_c += constant_c.x & (PGS_SUBPIXELS_RASTER - 1);

    int error_flip_b = 0;
    int error_flip_c = 0;
    if (parallelogram)
    {
        int tie_break_offset = 1 - int(tie_break_b) - int(tie_break_c);
        error_flip_b = tie_break_offset + error_b + error_a;
        error_flip_c = tie_break_offset + error_c + error_a;
        error_flip_b += PGS_SUBPIXELS_RASTER; // Ensure positive result. Compensate in raster.
        error_flip_c += PGS_SUBPIXELS_RASTER; // Ensure positive result. Compensate in raster.
        error_flip_b >>= PGS_SUBPIXEL_RASTER_BITS;
        error_flip_c >>= PGS_SUBPIXEL_RASTER_BITS;
    }

    float inv_area = rcp_fixed(area);
    precise float inv_area_scaled = inv_area * float(PGS_SUBPIXELS_RASTER);
    precise float error_i = float(error_b) * inv_area;
    precise float error_j = float(error_c) * inv_area;

    if (sprite)
    {
        zb = za;
        zc = za;
    }
    else if (line)
    {
        zc = za;
    }

    if (fix || sprite)
        order = ivec3(0, 1, 2);

    VertexAttribute attr0 = vertex_attr.data[3u * index + order.x];
    VertexAttribute attr1 = vertex_attr.data[3u * index + order.y];
    VertexAttribute attr2;
    if (!sprite && !line)
        attr2 = vertex_attr.data[3u * index + order.z];

    vec4 stqf0, stqf1, stqf2;
    if (perspective)
    {
        stqf0 = vec4(attr0.st, attr0.q, attr0.fog);
        stqf1 = vec4(attr1.st, attr1.q, attr1.fog);
        if (!sprite && !line)
            stqf2 = vec4(attr2.st, attr2.q, attr2.fog);
    }
    else
    {
        stqf0 = vec4(unpack_uv(attr0.uv), attr0.q, attr0.fog);
        stqf1 = vec4(unpack_uv(attr1.uv), attr1.q, attr1.fog);
        if (!sprite && !line)
            stqf2 = vec4(unpack_uv(attr2.uv), attr2.q, attr2.fog);
    }

    // +U follows X, +V follows Y it seems ...
    if (sprite)
    {
        // Need to apply the YZ flip ourselves since we're synthesizing the attributes.
        if (signed_area.y < 0)
        {
            stqf2 = vec4(stqf1.x, stqf0.yzw);
            stqf1 = vec4(stqf0.x, stqf1.y, stqf0.zw);
        }
        else
        {
            stqf2 = vec4(stqf0.x, stqf1.y, stqf0.zw);
            stqf1 = vec4(stqf1.x, stqf0.yzw);
        }
    }
    else if (line)
    {
        stqf2 = stqf0;
    }

    if (perspective)
    {
        // Negative Q is allowed, but they all have to match sign.
        // This should be fine.
        if (stqf0.z < 0.0)
        {
            stqf0.xy = -stqf0.xy;
            stqf1.xy = -stqf1.xy;
            stqf2.xy = -stqf2.xy;
        }

        stqf0.z = abs(stqf0.z);
        stqf1.z = abs(stqf1.z);
        stqf2.z = abs(stqf2.z);

        uint qbits = floatBitsToUint(max(max(stqf0.z, stqf1.z), stqf2.z));
        uint qexp = bitfieldExtract(qbits, 23, 8);

        // 8-bit mantissa for Q is rounded down.
        stqf0.z = uintBitsToFloat(floatBitsToUint(stqf0.z) & ~0xffu);
        stqf1.z = uintBitsToFloat(floatBitsToUint(stqf1.z) & ~0xffu);
        stqf2.z = uintBitsToFloat(floatBitsToUint(stqf2.z) & ~0xffu);

        // Apparently ST is rounded depending on how large Q is.
        // This suggests a re-scaling operation into fixed point in hardware.
        // This would make a lot of sense, since interpolating in FP on a DDA archicture would be exceptionally strange.
        // This exact formulation is very unlikely to be HW accurate, but it feels like a reasonable approximation
        // if I had to write a fixed point interpolator myself.
        // With rescaling and flipping signs (Q has to have uniform sign),
        // Q could be represented in 16-bit uint with 0x8000 representing 2^n, with 15 mantissa bits left from the quantize.
        uint sexp = bitfieldExtract(floatBitsToUint(max(max(abs(stqf0.x), abs(stqf1.x)), abs(stqf2.x))), 23, 8);
        uint texp = bitfieldExtract(floatBitsToUint(max(max(abs(stqf0.y), abs(stqf1.y)), abs(stqf2.y))), 23, 8);

        // 9 bits is apparently suggested by HW tests. I cannot confirm or verify this.
        // It does make sense if we consider that S/T might be quantized to 16-bit sint.
        // If we take into account that UV should be clamped to +/- 2047.0, these results start making more sense.
        // Consider 1 bit for sign, 0x4000 marking 1.0, and 14 mantissa bits left.
        // S = 1.0 + 2^-14, Q = 1.0 could be represented as 0x4001.
        // For large S, we could store an extra shift factor. We already shift up the result by TW/TH,
        // so folding that exponential shift in for normalized textures make a lot of sense.
        // For small S, S could be scaled in fixed point so the shifter can be a pure left shift.
        // Seems reasonable from a hardware design PoV.
        uint schop = min(9 + max(sexp, qexp) - sexp, 23);
        uint tchop = min(9 + max(texp, qexp) - texp, 23);
        uint smask = (1u << schop) - 1u;
        uint tmask = (1u << tchop) - 1u;
        uvec2 stmask = ~uvec2(smask, tmask);

        stqf0.xy = uintBitsToFloat(floatBitsToUint(stqf0.xy) & stmask);
        stqf1.xy = uintBitsToFloat(floatBitsToUint(stqf1.xy) & stmask);
        stqf2.xy = uintBitsToFloat(floatBitsToUint(stqf2.xy) & stmask);

        // For trivial perspective, we should strive for maximum accuracy, since some games rely on that.
        // Resolve the perspective in highest possible accuracy.
        // With fixed RCP, we can get essentially 24.0 bits, but without we have to rely on ~22.5 bit RCP
        // with different behavior per vendor.
        //
        // Technically, we should do perspective divider after interpolation,
        // but this is at least mathematically equivalent.
        // This level of accuracy only seems to matter in extreme single STQ value scenarios anyway.
        uint tex2_state = primitive_attr.data[index].tex2;
        bool needs_lod_computation = bitfieldExtract(tex2_state, TEX2_FIXED_LOD_OFFSET, TEX2_FIXED_LOD_BITS) == 0;
        if (!needs_lod_computation && stqf0.z == stqf1.z && stqf0.z == stqf2.z)
        {
            float inv_q = rcp_float(stqf0.z);
            stqf0.xy *= inv_q;
            stqf1.xy *= inv_q;
            stqf2.xy *= inv_q;
            stqf0.z = 1.0;
            stqf1.z = 1.0;
            stqf2.z = 1.0;
        }
    }

    precise vec4 distqf = fix ? vec4(0.0) : (stqf1 - stqf0);
    precise vec4 djstqf = fix ? vec4(0.0) : (stqf2 - stqf0);

    transformed_attr.data[index].stqf0 = stqf0;
    transformed_attr.data[index].stqf1 = distqf;
    transformed_attr.data[index].stqf2 = djstqf;

    if (iip && !sprite)
    {
        if (fix)
            attr1.rgba = attr0.rgba;
        if (fix || line)
            attr2.rgba = attr0.rgba;
        transformed_attr.data[index].rgba0 = attr0.rgba;
        transformed_attr.data[index].rgba1 = attr1.rgba;
        transformed_attr.data[index].rgba2 = attr2.rgba;
    }
    else
    {
        uint flat_rgba = vertex_attr.data[3u * index].rgba;
        transformed_attr.data[index].rgba0 = flat_rgba;
        transformed_attr.data[index].rgba1 = flat_rgba;
        transformed_attr.data[index].rgba2 = flat_rgba;
    }

    transformed_attr.data[index].padding = 0; // Avoid striped cache-line writeback.

    ivec3 plane_a = quantize_step(dadx, dady, constant_a);
    ivec3 plane_b = quantize_step(dbdx, dbdy, constant_b);
    ivec3 plane_c = quantize_step(dcdx, dcdy, constant_c);

    plane_a.x = bitfieldInsert(plane_a.x << 6, int(parallelogram), 0, 1);
    plane_a.x = bitfieldInsert(plane_a.x, error_flip_b, 2, 2);
    plane_a.x = bitfieldInsert(plane_a.x, error_flip_c, 4, 2);

    primitive_setup.data[index].a = plane_a;
    primitive_setup.data[index].inv_area = inv_area_scaled;
    primitive_setup.data[index].b = plane_b;
    primitive_setup.data[index].error_i = error_i;
    primitive_setup.data[index].c = plane_c;
    primitive_setup.data[index].error_j = error_j;
    // This will be fine as long as we assume that the primitive doesn't have an insane range in 32-bit Z.
    // We get ideal accuracy on the lowest Z, i.e. closer to far plane, which should be ideal, since that's where
    // precision is needed.
    primitive_setup.data[index].z = uvec4(za, floatBitsToUint(float(zb - za)), floatBitsToUint(float(zc - za)), 0);

    ivec2 d = parallelogram ? (b + c - a) : c;
    ivec4 packed_bb = pack_bounding_box(a, b, c, d, multisample, SAMPLING_RATE_LOG2);

    packed_bb = clip_bounding_box(packed_bb, ivec4(primitive_attr.data[index].bb));
    primitive_setup.data[index].bb = packed_bb;

    if (sprite && !perspective)
    {
        // In some odd cases, a game really should have used NEAREST filter.
        // Detecting this is important since at least one game in the wild seems to barely touch the neighbor sub-texel
        // wreacking havok in channel shuffle effects.
        // Resolving this with pure interpolation requires near-infinite precision, which we don't have.
        ivec2 uv_delta0 = ivec2(attr0.uv) - a;
        ivec2 uv_delta1 = ivec2(attr1.uv) - d;
        ivec2 min_delta = min(uv_delta0, uv_delta1);
        ivec2 max_delta = max(uv_delta0, uv_delta1);

        bool half_texel_offset = all(equal(min_delta & (PGS_SUBPIXELS - 1), ivec2(PGS_SUBPIXELS >> 1)));

        // If we only deviate by one sub-texel, interpolation will very likely never hit that upper value.
        // Since we snap down to the minimum value either way.
        bool no_effective_interpolation = all(lessThanEqual(max_delta - min_delta, ivec2(1)));

        if (half_texel_offset && no_effective_interpolation)
            primitive_attr.data[index].tex &= ~TEX_SAMPLER_MAG_LINEAR_BIT;
    }

    if (SAMPLING_RATE_LOG2 != 0 && !sprite)
    {
        // Try to detect common patterns of flat UI primitives.
        // In this case, we should aim to snap attribute interpolation to avoid common glitches.
        // There is no point in upsampling UI elements anyway.
        // Filtering it further will only look worse and less sharp than the native alternative.
        bool should_interpolate_per_sample = multisample;

        // If there is any proof of 3D-ness, like perspective, or different Z values, we're most likely rendering 3D.
        if (!should_interpolate_per_sample && perspective)
            should_interpolate_per_sample = distqf.z != 0.0 || djstqf.z != 0.0;
        if (!should_interpolate_per_sample)
            should_interpolate_per_sample = za != zb || zb != zc;

        if (!should_interpolate_per_sample)
        {
            uint rp_instance = bitfieldExtract(primitive_attr.data[index].state,
                                               STATE_VERTEX_RENDER_PASS_INSTANCE_OFFSET,
                                               STATE_VERTEX_RENDER_PASS_INSTANCE_COUNT);

            uint z_shift = bitfieldExtract(registers.packed_z_shift, 4 * int(rp_instance), 4) * 8;

            // Don't demote lines unless we demote the entire render pass to single sampled.
            if (!line)
                primitive_attr.data[index].state |= 1u << STATE_BIT_SNAP_ATTRIBUTE;

            // Also need to compute the ST bounding box.
            // This is important for UI elements to make sure we don't interpolate outside the expected region.
            // Compute ST at the single-sample bounding box.
            ivec4 packed_bb_single = pack_bounding_box(a, b, c, d, false, 0);

            // Sample IJ at all BB points. This forms our barycentric bounds.
            // For rotated primitives, this will lead to way-out-of-bounds IJ, but that's fine.
            // Rotated primitives are rarely UI elements.
            vec2 ij00 = evaluate_barycentric_ij(plane_b, plane_c, inv_area_scaled, error_i, error_j,
                                                packed_bb_single.xy, 0);
            vec2 ij10 = evaluate_barycentric_ij(plane_b, plane_c, inv_area_scaled, error_i, error_j,
                                                packed_bb_single.zy, 0);
            vec2 ij01 = evaluate_barycentric_ij(plane_b, plane_c, inv_area_scaled, error_i, error_j,
                                                packed_bb_single.xw, 0);
            vec2 ij11 = evaluate_barycentric_ij(plane_b, plane_c, inv_area_scaled, error_i, error_j,
                                                packed_bb_single.zw, 0);

            vec2 st00 = stqf0.xy + distqf.xy * ij00.x + djstqf.xy * ij00.y;
            vec2 st10 = stqf0.xy + distqf.xy * ij10.x + djstqf.xy * ij10.y;
            vec2 st01 = stqf0.xy + distqf.xy * ij01.x + djstqf.xy * ij01.y;
            vec2 st11 = stqf0.xy + distqf.xy * ij11.x + djstqf.xy * ij11.y;

            vec2 lo_st = min(min(st00, st10), min(st01, st11));
            vec2 hi_st = max(max(st00, st10), max(st01, st11));
            transformed_attr.data[index].st_bb = vec4(lo_st, hi_st);

            // Need to clamp in case primitive Z overflows. In that case, we get saturation.
            uint single_sampled_bucket_index = min(255u, za >> z_shift);
            uint bucket_index_hi = single_sampled_bucket_index / 32u;
            uint bucket_index_lo = single_sampled_bucket_index % 32u;

            // Could be clever and do waterfall atomic, but primitive count is low enough that we don't really care.
            // Each flat primitive falls into one of 256 buckets.
            // Every bucket should hold up to 64k depth values.
            // This matches well with LDS since we'll need to hold 2 KiB for negative mask.
            uint old_value = atomicOr(
                    heuristic.data.active_depth_range_mask_atomic[bucket_index_hi],
                    1u << bucket_index_lo);

            if (bitfieldExtract(old_value, int(bucket_index_lo), 1) == 0)
            {
                // We're the first thread that touched this bucket, we'll need to allocate a new indirect bucket.
                uint offset = atomicAdd(heuristic.data.single_sample_fixup_indirect.x, 1u);
                heuristic.data.depth_range_offset[offset] = single_sampled_bucket_index;
                if (offset == 0u)
                {
                    // First thread that allocated a bucket, setup the indirect args.
                    heuristic.data.single_sample_fixup_indirect.y = 1u;
                    heuristic.data.single_sample_fixup_indirect.z = 1u;
                }
            }
        }
    }
}

void main()
{
    uint index = gl_GlobalInvocationID.x;
    if (index < registers.num_primitives)
        main_inner(index);
}
