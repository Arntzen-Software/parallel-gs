#version 450

// SPDX-FileCopyrightText: 2024 Arntzen Software AS
// SPDX-FileContributor: Hans-Kristian Arntzen
// SPDX-FileContributor: Runar Heyer
// SPDX-License-Identifier: LGPL-3.0+

#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_scalar_block_layout : require

layout(local_size_x_id = 0) in;
layout(constant_id = 1) const uint SOURCE_FMT = 0;
layout(constant_id = 2) const uint STORAGE_FMT = 0;
layout(constant_id = 3) const uint VRAM_MASK = 4 * 1024 * 1024 - 1;
layout(constant_id = 4) const uint TRANSFER_DIR = 0;
layout(constant_id = 5) const bool INVALIDATE_SUPER_SAMPLE = false;

#include "utils.h"
#include "swizzle_utils.h"
#include "data_structures.h"

const bool is_tex_32bit = STORAGE_FMT == PSMCT32 || STORAGE_FMT == PSMZ32;
const bool is_tex_24bit = STORAGE_FMT == PSMCT24 || STORAGE_FMT == PSMZ24;
const bool is_tex_16bit = STORAGE_FMT == PSMCT16 || STORAGE_FMT == PSMCT16S ||
	STORAGE_FMT == PSMZ16 || STORAGE_FMT == PSMZ16S;
const bool is_tex_8bit = STORAGE_FMT == PSMT8 || STORAGE_FMT == PSMT8H;

layout(std430, set = 0, binding = 0) buffer VRAM32
{
	uint data[];
} vram32;

layout(std430, set = 0, binding = 0) buffer VRAM24
{
	u8vec3 data[];
} vram24;

layout(std430, set = 0, binding = 0) buffer VRAM16
{
	uint16_t data[];
} vram16;

layout(std430, set = 0, binding = 0) buffer VRAM8
{
	uint8_t data[];
} vram8;

layout(std430, set = 0, binding = 1) readonly buffer TRANSFER32
{
	uint data[];
} transfer32;

layout(scalar, set = 0, binding = 1) readonly buffer TRANSFER24
{
	u8vec3 data[];
} transfer24;

layout(std430, set = 0, binding = 1) readonly buffer TRANSFER16
{
	uint16_t data[];
} transfer16;

layout(std430, set = 0, binding = 1) readonly buffer TRANSFER8
{
	uint8_t data[];
} transfer8;

layout(std140, set = 0, binding = 2) uniform TransferDesc
{
	TransferDescriptor transfer;
};

// Workaround glslang issue with 8/16-bit constants and storage.
layout(constant_id = 7) const uint CONSTANT_ZERO = 0;

void main()
{
	ivec2 coord;
	coord.x = int(gl_WorkGroupID.x * 8 + bitfieldExtract(gl_LocalInvocationIndex, 0, 3));

	if (gl_WorkGroupSize.x == 64)
		coord.y = int(gl_WorkGroupID.y * 8 + bitfieldExtract(gl_LocalInvocationIndex, 3, 3));
	else
	{
		coord.y = int(gl_WorkGroupID.y * 4 + bitfieldExtract(gl_LocalInvocationIndex, 3, 2));
		// Skip odd-numbered addresses; both nibbles are handled in the even-numbered lookups
		coord.y = ((coord.y & ~0x1) << 1) | (coord.y & 0x1); // Bit y1 is LSB in nibble address swizzle pattern
	}

	if (coord.x >= transfer.width || coord.y >= transfer.height)
		return;

	// Transmission area coordinates (start + offset) wrap around at 2048
	uint source_x = (coord.x + transfer.source_x) & (2048 - 1);
	uint source_y = (coord.y + transfer.source_y) & (2048 - 1);
	uint dest_x = (coord.x + transfer.dest_x) & (2048 - 1);
	uint dest_y = (coord.y + transfer.dest_y) & (2048 - 1);

	uint source_addr;
	if (TRANSFER_DIR == HOST_TO_LOCAL)
	{
		source_addr = coord.y * transfer.width + coord.x;
	}
	else if (TRANSFER_DIR == LOCAL_TO_LOCAL)
	{
		source_addr = swizzle_PS2(source_x, source_y, transfer.source_addr, transfer.source_stride, SOURCE_FMT,
			VRAM_MASK);
	}

	uint dest_addr = swizzle_PS2(dest_x, dest_y, transfer.dest_addr, transfer.dest_stride, STORAGE_FMT, VRAM_MASK);

	if (is_tex_24bit)
	{
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 2 < transfer.host_offset_qwords)
			return;

		uint tex_data;
		if (TRANSFER_DIR == HOST_TO_LOCAL)
		{
			// Drop writes that were skipped in upload.
			if (source_addr >= transfer24.data.length())
				return;

			uvec3 bytes = uvec3(transfer24.data[source_addr]);
			tex_data = bytes.x | (bytes.y << 8) | (bytes.z << 16);
		}
		else
		{
			tex_data = uint(transfer32.data[source_addr]);
		}

		vram24.data[dest_addr] = u8vec3(uvec3(tex_data) >> uvec3(0, 8, 16));
		if (INVALIDATE_SUPER_SAMPLE)
			vram32.data[dest_addr + (VRAM_MASK + 1) / 4] = 0; // Don't care about trying to preserve SSAA for top bit only.
	}
	else if (is_tex_16bit)
	{
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 4 < transfer.host_offset_qwords)
			return;
		if (TRANSFER_DIR != HOST_TO_LOCAL || source_addr < transfer16.data.length())
		{
			uint write_word = uint(transfer16.data[source_addr]);
			vram16.data[dest_addr] = uint16_t(write_word);
			if (INVALIDATE_SUPER_SAMPLE)
				vram16.data[dest_addr + (VRAM_MASK + 1) / 2] = uint16_t(write_word & CONSTANT_ZERO);
		}
	}
	else if (is_tex_8bit)
	{
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 8 < transfer.host_offset_qwords)
			return;

		uint source_offset = 0;
		if (TRANSFER_DIR == LOCAL_TO_LOCAL && SOURCE_FMT == PSMT8H)
		{
			source_addr <<= 2;
			source_offset = 3;
		}

		uint dest_offset = 0;
		if (STORAGE_FMT == PSMT8H)
		{
			dest_addr <<= 2;
			dest_offset = 3;
		}

		if (TRANSFER_DIR != HOST_TO_LOCAL || source_addr + source_offset < transfer8.data.length())
		{
			uint d = uint(transfer8.data[source_addr + source_offset]);
			vram8.data[dest_addr + dest_offset] = uint8_t(d);
			if (INVALIDATE_SUPER_SAMPLE)
				vram8.data[dest_addr + dest_offset + (VRAM_MASK + 1)] = uint8_t(d & CONSTANT_ZERO);
		}
	}
	else if (STORAGE_FMT == PSMT4 && gl_WorkGroupSize.x == 32)
	{
		// Fused nibble approach
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 16 < transfer.host_offset_qwords)
			return;

		// Find corresponding second nibble within the column so two pixels (nibbles) can be written at once
		ivec2 coord_hi = coord ^ ivec2(4, 2);
		uint write_word;

		if (TRANSFER_DIR == HOST_TO_LOCAL)
		{
			if (source_addr >= 2 * transfer8.data.length())
				return;

			uint source_data_lo = uint(transfer8.data[source_addr >> 1]);
			uint source_addr_hi = coord_hi.y * transfer.width + coord_hi.x;
			uint source_data_hi = uint(transfer8.data[source_addr_hi >> 1]);

			if ((source_addr_hi & 1u) == 0)
				source_data_hi <<= 4;
			else
				source_data_lo >>= 4;

			write_word = bitfieldInsert(source_data_hi, source_data_lo, 0, 4);
		}
		else if (TRANSFER_DIR == LOCAL_TO_LOCAL)
		{
			if (SOURCE_FMT == PSMT4)
			{
				write_word = uint(transfer8.data[source_addr >> 1]);
			}
			else if (SOURCE_FMT == PSMT4HH || SOURCE_FMT == PSMT4HL)
			{
				int source_offset = SOURCE_FMT == PSMT4HL ? 24 : 28;
				uint source_data_lo = bitfieldExtract(transfer32.data[source_addr], source_offset, 4);
				uint pair_addr = swizzle_PS2(coord_hi.x + transfer.source_x, coord_hi.y + transfer.source_y,
					transfer.source_addr, transfer.source_stride, SOURCE_FMT, VRAM_MASK);
				uint source_data_hi = bitfieldExtract(int(transfer32.data[pair_addr]), source_offset, 4) << 4;
				write_word = bitfieldInsert(source_data_hi, source_data_lo, 0, 4);
			}
		}
		vram8.data[dest_addr >> 1] = uint8_t(write_word);
		if (INVALIDATE_SUPER_SAMPLE)
			vram8.data[(dest_addr >> 1) + (VRAM_MASK + 1)] = uint8_t(write_word & CONSTANT_ZERO);
	}
	else if (STORAGE_FMT == PSMT4)
	{
		// Fallback, sub-word atomics.
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 16 < transfer.host_offset_qwords)
			return;

		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr >= 2 * transfer8.data.length())
			return;

		uint source_data;
		if (SOURCE_FMT == PSMT4 || TRANSFER_DIR == HOST_TO_LOCAL)
		{
			source_data = uint(transfer8.data[source_addr >> 1]);
			source_data = bitfieldExtract(source_data, 4 * int(source_addr & 1u), 4);
		}
		else
		{
			int source_offset = SOURCE_FMT == PSMT4HL ? 24 : 28;
			source_data = bitfieldExtract(transfer32.data[source_addr], source_offset, 4);
		}

		uint shamt = 4u * (dest_addr & 7u);
		uint mask = 0xfu << shamt;

		atomicAnd(vram32.data[dest_addr >> 3], ~mask);
		atomicOr(vram32.data[dest_addr >> 3], source_data << shamt);

		if (INVALIDATE_SUPER_SAMPLE)
			atomicAnd(vram32.data[(dest_addr >> 3) + (VRAM_MASK + 1) / 4], ~mask);
	}
	else if (STORAGE_FMT == PSMT4HL || STORAGE_FMT == PSMT4HH)
	{
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 16 < transfer.host_offset_qwords)
			return;
		int dest_offset = STORAGE_FMT == PSMT4HL ? 24 : 28;
		uint source_data;
		if (TRANSFER_DIR == HOST_TO_LOCAL)
		{
			if (source_addr >= transfer8.data.length() * 2)
				return;
			source_data = bitfieldExtract(uint(transfer8.data[source_addr >> 1u]), int(source_addr & 1u) * 4, 4);
		}
		else if (TRANSFER_DIR == LOCAL_TO_LOCAL)
		{
			if (SOURCE_FMT == PSMT4)
			{
				int source_offset = int(source_addr & 1u) << 2;
				source_data = bitfieldExtract(uint(transfer8.data[source_addr >> 1]), source_offset, 4);
			}
			else
			{
				int source_offset = SOURCE_FMT == PSMT4HL ? 24 : 28;
				source_data = bitfieldExtract(transfer32.data[source_addr], source_offset, 4);
			}
		}

		uint dest_data = vram32.data[dest_addr];
		vram32.data[dest_addr] = bitfieldInsert(dest_data, source_data, dest_offset, 4);
		if (INVALIDATE_SUPER_SAMPLE)
			vram32.data[dest_addr + (VRAM_MASK + 1) / 4] &= 0xffffff;
	}
	else
	{
		if (TRANSFER_DIR == HOST_TO_LOCAL && source_addr * 2 < transfer.host_offset_qwords)
			return;

		if (TRANSFER_DIR != HOST_TO_LOCAL || source_addr < transfer32.data.length())
		{
			vram32.data[dest_addr] = transfer32.data[source_addr];
			if (INVALIDATE_SUPER_SAMPLE)
				vram32.data[dest_addr + (VRAM_MASK + 1) / 4] = 0;
		}
	}
}